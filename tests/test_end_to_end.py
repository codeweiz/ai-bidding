#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä»æ‹›æ ‡ä¹¦åˆ°æ ‡ä¹¦çš„å®Œæ•´æµç¨‹æµ‹è¯•
"""

import shutil
import tempfile
import time
from pathlib import Path

import pytest

from backend.services.content_generator import content_generator
from backend.services.document_parser import document_parser
from backend.services.llm_service import llm_service


class TestEndToEndWorkflow:
    """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•"""

    @pytest.fixture(autouse=True)
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = Path(tempfile.mkdtemp())
        self.test_uploads_dir = self.temp_dir / "uploads"
        self.test_outputs_dir = self.temp_dir / "outputs"

        self.test_uploads_dir.mkdir(exist_ok=True)
        self.test_outputs_dir.mkdir(exist_ok=True)

        # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
        self.test_doc_path = self.test_uploads_dir / "test_bidding_document.txt"
        self.test_doc_content = """æ™ºæ…§åŸå¸‚ç»¼åˆç®¡ç†å¹³å°å»ºè®¾é¡¹ç›®æ‹›æ ‡æ–‡ä»¶

ä¸€ã€é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®æ—¨åœ¨å»ºè®¾ä¸€å¥—æ™ºæ…§åŸå¸‚ç»¼åˆç®¡ç†å¹³å°ï¼Œå®ç°åŸå¸‚å„ç±»æ•°æ®çš„ç»Ÿä¸€ç®¡ç†ã€åˆ†æå’Œå±•ç¤ºã€‚

äºŒã€æŠ€æœ¯éœ€æ±‚
1. ç³»ç»Ÿæ¶æ„è¦æ±‚
- é‡‡ç”¨å¾®æœåŠ¡æ¶æ„è®¾è®¡
- æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²
- å…·å¤‡é«˜å¯ç”¨æ€§å’Œå¯æ‰©å±•æ€§

2. åŠŸèƒ½éœ€æ±‚
- æ•°æ®é‡‡é›†æ¨¡å—ï¼šæ”¯æŒå¤šç§æ•°æ®æºæ¥å…¥
- æ•°æ®å¤„ç†æ¨¡å—ï¼šå®æ—¶æ•°æ®å¤„ç†å’Œåˆ†æ
- å¯è§†åŒ–å±•ç¤ºï¼šæä¾›ä¸°å¯Œçš„å›¾è¡¨å’Œå¤§å±å±•ç¤º
- ç”¨æˆ·ç®¡ç†ï¼šæ”¯æŒå¤šçº§ç”¨æˆ·æƒé™ç®¡ç†

3. æ€§èƒ½æŒ‡æ ‡
- ç³»ç»Ÿå¹¶å‘ç”¨æˆ·æ•°ï¼šä¸å°‘äº1000äºº
- æ•°æ®å¤„ç†å»¶è¿Ÿï¼šä¸è¶…è¿‡3ç§’
- ç³»ç»Ÿå¯ç”¨æ€§ï¼š99.9%ä»¥ä¸Š

4. æŠ€æœ¯æ ˆè¦æ±‚
- åç«¯ï¼šJava Spring Bootæˆ–Python Django
- å‰ç«¯ï¼šVue.jsæˆ–React
- æ•°æ®åº“ï¼šMySQLæˆ–PostgreSQL
- ç¼“å­˜ï¼šRedis
- æ¶ˆæ¯é˜Ÿåˆ—ï¼šRabbitMQæˆ–Kafka

ä¸‰ã€è¯„åˆ†æ ‡å‡†
1. æŠ€æœ¯æ–¹æ¡ˆï¼ˆ40åˆ†ï¼‰
- æ¶æ„è®¾è®¡åˆç†æ€§
- æŠ€æœ¯é€‰å‹å…ˆè¿›æ€§
- ç³»ç»Ÿå®‰å…¨æ€§

2. å®æ–½æ–¹æ¡ˆï¼ˆ30åˆ†ï¼‰
- é¡¹ç›®è®¡åˆ’è¯¦ç»†ç¨‹åº¦
- é£é™©æ§åˆ¶æªæ–½
- è´¨é‡ä¿è¯ä½“ç³»

3. å›¢é˜Ÿå®åŠ›ï¼ˆ20åˆ†ï¼‰
- é¡¹ç›®ç»éªŒ
- æŠ€æœ¯èƒ½åŠ›
- å›¢é˜Ÿè§„æ¨¡

4. å•†åŠ¡æŠ¥ä»·ï¼ˆ10åˆ†ï¼‰
- ä»·æ ¼åˆç†æ€§
- æ€§ä»·æ¯”

å››ã€é¡¹ç›®å‘¨æœŸ
é¡¹ç›®æ€»å·¥æœŸä¸º6ä¸ªæœˆï¼Œåˆ†ä¸ºä»¥ä¸‹é˜¶æ®µï¼š
1. éœ€æ±‚åˆ†æå’Œè®¾è®¡é˜¶æ®µï¼ˆ1ä¸ªæœˆï¼‰
2. å¼€å‘é˜¶æ®µï¼ˆ3ä¸ªæœˆï¼‰
3. æµ‹è¯•é˜¶æ®µï¼ˆ1ä¸ªæœˆï¼‰
4. éƒ¨ç½²å’ŒéªŒæ”¶é˜¶æ®µï¼ˆ1ä¸ªæœˆï¼‰

äº”ã€äº¤ä»˜è¦æ±‚
1. å®Œæ•´çš„ç³»ç»Ÿæºä»£ç 
2. è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£
3. ç”¨æˆ·æ“ä½œæ‰‹å†Œ
4. ç³»ç»Ÿéƒ¨ç½²æ–‡æ¡£
5. åŸ¹è®­æœåŠ¡
"""

        # å†™å…¥æµ‹è¯•æ–‡æ¡£
        with open(self.test_doc_path, 'w', encoding='utf-8') as f:
            f.write(self.test_doc_content)

        yield

        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_document_parsing(self):
        """æµ‹è¯•æ–‡æ¡£è§£æåŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•æ–‡æ¡£è§£æåŠŸèƒ½...")

        # è§£ææ–‡æ¡£
        result = document_parser.parse_document(self.test_doc_path)

        # éªŒè¯è§£æç»“æœ
        assert isinstance(result, dict), "è§£æç»“æœåº”è¯¥æ˜¯å­—å…¸ç±»å‹"
        assert "file_name" in result, "è§£æç»“æœåº”åŒ…å«æ–‡ä»¶å"
        assert "documents" in result, "è§£æç»“æœåº”åŒ…å«æ–‡æ¡£å†…å®¹"
        assert "chunks" in result, "è§£æç»“æœåº”åŒ…å«æ–‡æ¡£åˆ†å—"
        assert "metadata" in result, "è§£æç»“æœåº”åŒ…å«å…ƒæ•°æ®"

        # éªŒè¯å…·ä½“å†…å®¹
        assert result["file_name"] == "test_bidding_document.txt"
        assert len(result["documents"]) > 0, "åº”è¯¥æœ‰æ–‡æ¡£å†…å®¹"
        assert len(result["chunks"]) > 0, "åº”è¯¥æœ‰æ–‡æ¡£åˆ†å—"

        print(f"âœ… æ–‡æ¡£è§£ææˆåŠŸï¼š{result['file_name']}")
        print(f"   - æ–‡æ¡£æ•°é‡: {len(result['documents'])}")
        print(f"   - åˆ†å—æ•°é‡: {len(result['chunks'])}")

        return result

    @pytest.mark.asyncio
    async def test_requirement_analysis(self):
        """æµ‹è¯•éœ€æ±‚åˆ†æåŠŸèƒ½"""
        print("\nğŸ§  æµ‹è¯•éœ€æ±‚åˆ†æåŠŸèƒ½...")

        # å…ˆè§£ææ–‡æ¡£
        parse_result = self.test_document_parsing()

        # æå–æ–‡æ¡£å†…å®¹
        content = "\n".join([doc.page_content for doc in parse_result["documents"]])

        # åˆ†æéœ€æ±‚
        analysis_result = await llm_service.analyze_requirements(content)

        # éªŒè¯åˆ†æç»“æœ
        assert isinstance(analysis_result, dict), "åˆ†æç»“æœåº”è¯¥æ˜¯å­—å…¸ç±»å‹"
        assert "status" in analysis_result, "åˆ†æç»“æœåº”åŒ…å«çŠ¶æ€"
        assert "analysis" in analysis_result, "åˆ†æç»“æœåº”åŒ…å«åˆ†æå†…å®¹"

        if analysis_result["status"] == "success":
            analysis = analysis_result["analysis"]
            assert isinstance(analysis, str), "åˆ†æå†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸²ç±»å‹"
            assert len(analysis) > 0, "åˆ†æå†…å®¹ä¸åº”ä¸ºç©º"

            print("âœ… éœ€æ±‚åˆ†ææˆåŠŸ")
            print(f"   - åˆ†æå†…å®¹é•¿åº¦: {len(analysis)} å­—ç¬¦")
            print(f"   - å†…å®¹é¢„è§ˆ: {analysis[:200]}...")
        else:
            print(f"âš ï¸ éœ€æ±‚åˆ†æå¤±è´¥: {analysis_result.get('error', 'Unknown error')}")

        return analysis_result

    @pytest.mark.asyncio
    async def test_outline_generation(self):
        """æµ‹è¯•æçº²ç”ŸæˆåŠŸèƒ½"""
        print("\nğŸ“‹ æµ‹è¯•æçº²ç”ŸæˆåŠŸèƒ½...")

        # å…ˆè¿›è¡Œéœ€æ±‚åˆ†æ
        analysis_result = await self.test_requirement_analysis()

        if analysis_result["status"] != "success":
            pytest.skip("éœ€æ±‚åˆ†æå¤±è´¥ï¼Œè·³è¿‡æçº²ç”Ÿæˆæµ‹è¯•")

        # ç”Ÿæˆæçº²
        requirements = analysis_result["analysis"]  # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦JSONåºåˆ—åŒ–
        outline_result = await llm_service.generate_outline(requirements)

        # éªŒè¯æçº²ç»“æœ
        assert isinstance(outline_result, dict), "æçº²ç»“æœåº”è¯¥æ˜¯å­—å…¸ç±»å‹"
        assert "status" in outline_result, "æçº²ç»“æœåº”åŒ…å«çŠ¶æ€"
        assert "outline" in outline_result, "æçº²ç»“æœåº”åŒ…å«æçº²å†…å®¹"

        if outline_result["status"] == "success":
            outline = outline_result["outline"]
            assert isinstance(outline, str), "æçº²å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸²ç±»å‹"
            assert len(outline) > 0, "æçº²å†…å®¹ä¸åº”ä¸ºç©º"

            print("âœ… æçº²ç”ŸæˆæˆåŠŸ")
            print(f"   - æçº²å†…å®¹é•¿åº¦: {len(outline)} å­—ç¬¦")
            print(f"   - å†…å®¹é¢„è§ˆ: {outline[:300]}...")
        else:
            print(f"âš ï¸ æçº²ç”Ÿæˆå¤±è´¥: {outline_result.get('error', 'Unknown error')}")

        return outline_result

    @pytest.mark.asyncio
    async def test_content_generation(self):
        """æµ‹è¯•å†…å®¹ç”ŸæˆåŠŸèƒ½"""
        print("\nğŸ“ æµ‹è¯•å†…å®¹ç”ŸæˆåŠŸèƒ½...")

        # å…ˆè¿›è¡Œéœ€æ±‚åˆ†æ
        analysis_result = await self.test_requirement_analysis()

        if analysis_result["status"] != "success":
            pytest.skip("éœ€æ±‚åˆ†æå¤±è´¥ï¼Œè·³è¿‡å†…å®¹ç”Ÿæˆæµ‹è¯•")

        # å†ç”Ÿæˆæçº²
        outline_result = await self.test_outline_generation()

        if outline_result["status"] != "success":
            pytest.skip("æçº²ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡å†…å®¹ç”Ÿæˆæµ‹è¯•")

        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„é¡¹ç›®å¯¹è±¡
        from backend.models.project import Project, ProjectStatus

        mock_project = Project(
            id="test_project_001",
            name="æ™ºæ…§åŸå¸‚ç»¼åˆç®¡ç†å¹³å°æµ‹è¯•é¡¹ç›®",
            description="ç«¯åˆ°ç«¯æµ‹è¯•é¡¹ç›®",
            company_name="æµ‹è¯•å…¬å¸",
            enable_differentiation=True,
            status=ProjectStatus.ANALYZING
        )

        # ç”Ÿæˆå†…å®¹
        generation_result = await content_generator.generate_proposal(
            project=mock_project,
            document_path=str(self.test_doc_path)
        )

        # éªŒè¯ç”Ÿæˆç»“æœ
        assert isinstance(generation_result, dict), "ç”Ÿæˆç»“æœåº”è¯¥æ˜¯å­—å…¸ç±»å‹"
        assert "status" in generation_result, "ç”Ÿæˆç»“æœåº”åŒ…å«çŠ¶æ€"

        if generation_result["status"] == "success":
            assert "document_path" in generation_result, "æˆåŠŸç»“æœåº”åŒ…å«æ–‡æ¡£è·¯å¾„"

            file_path = Path(generation_result["document_path"])
            assert file_path.exists(), "ç”Ÿæˆçš„æ–‡ä»¶åº”è¯¥å­˜åœ¨"
            assert file_path.suffix == ".docx", "ç”Ÿæˆçš„æ–‡ä»¶åº”è¯¥æ˜¯Wordæ ¼å¼"

            print("âœ… å†…å®¹ç”ŸæˆæˆåŠŸ")
            print(f"   - è¾“å‡ºæ–‡ä»¶: {file_path.name}")
            print(f"   - æ–‡ä»¶å¤§å°: {file_path.stat().st_size} bytes")
        else:
            print(f"âš ï¸ å†…å®¹ç”Ÿæˆå¤±è´¥: {generation_result.get('error', 'Unknown error')}")

        return generation_result

    @pytest.mark.asyncio
    async def test_full_workflow(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
        print("\nğŸš€ æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹...")

        start_time = time.time()

        try:
            # 1. æ–‡æ¡£è§£æ
            print("æ­¥éª¤ 1/4: æ–‡æ¡£è§£æ")
            parse_result = self.test_document_parsing()

            # 2. éœ€æ±‚åˆ†æ
            print("æ­¥éª¤ 2/4: éœ€æ±‚åˆ†æ")
            analysis_result = await self.test_requirement_analysis()

            # 3. æçº²ç”Ÿæˆ
            print("æ­¥éª¤ 3/4: æçº²ç”Ÿæˆ")
            outline_result = await self.test_outline_generation()

            # 4. å†…å®¹ç”Ÿæˆ
            print("æ­¥éª¤ 4/4: å†…å®¹ç”Ÿæˆ")
            generation_result = await self.test_content_generation()

            end_time = time.time()
            total_time = end_time - start_time

            print(f"\nğŸ‰ å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•å®Œæˆ!")
            print(f"   - æ€»è€—æ—¶: {total_time:.2f} ç§’")

            # éªŒè¯æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸ
            assert parse_result is not None
            if analysis_result["status"] == "success":
                assert outline_result["status"] == "success"
                assert generation_result["status"] == "success"
                print("   - æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸå®Œæˆ âœ…")
            else:
                print("   - éƒ¨åˆ†æ­¥éª¤å¤±è´¥ï¼Œä½†æ–‡æ¡£è§£ææˆåŠŸ âš ï¸")

        except Exception as e:
            print(f"âŒ å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {str(e)}")
            raise


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "-s"])
