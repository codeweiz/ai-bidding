# AI投标方案生成系统 - 部署运维指南

## 📋 文档信息
- **文档版本**：v2.0
- **适用环境**：开发、测试、生产
- **最后更新**：2025-07-02
- **维护团队**：AI投标系统开发团队

## 📋 目录
- [1. 环境要求](#1-环境要求)
- [2. 快速部署](#2-快速部署)
- [3. 生产环境部署](#3-生产环境部署)
- [4. 配置管理](#4-配置管理)
- [5. 监控告警](#5-监控告警)
- [6. 日志管理](#6-日志管理)
- [7. 备份恢复](#7-备份恢复)
- [8. 故障排除](#8-故障排除)

## 1. 环境要求

### 1.1 硬件要求

#### 开发环境
- **CPU**：2核心以上
- **内存**：4GB以上
- **存储**：20GB可用空间
- **网络**：稳定的互联网连接

#### 测试环境
- **CPU**：4核心以上
- **内存**：8GB以上
- **存储**：50GB可用空间
- **网络**：稳定的互联网连接

#### 生产环境
- **CPU**：8核心以上
- **内存**：16GB以上
- **存储**：100GB可用空间（SSD推荐）
- **网络**：高速稳定网络连接
- **负载均衡**：支持多实例部署

### 1.2 软件要求

#### 基础软件
- **操作系统**：Ubuntu 20.04+ / CentOS 8+ / macOS 10.15+
- **Docker**：20.0+
- **Docker Compose**：2.0+
- **Python**：3.11+（如果本地开发）

#### 外部依赖
- **PostgreSQL**：15+
- **Redis**：7+
- **Nginx**：1.20+（生产环境）

### 1.3 网络要求
- **端口开放**：
  - 8000 (后端API)
  - 7860 (前端界面)
  - 5555 (Celery监控)
  - 5432 (PostgreSQL)
  - 6379 (Redis)
  - 80/443 (Nginx)

## 2. 快速部署

### 2.1 开发环境部署

#### 2.1.1 克隆代码
```bash
git clone https://github.com/your-org/ai-bidding.git
cd ai-bidding
```

#### 2.1.2 配置环境
```bash
# 复制配置文件
cp config.toml.example config.toml

# 编辑配置文件，设置API密钥
vim config.toml
```

#### 2.1.3 启动服务
```bash
# 使用增强版启动脚本
./start_enhanced.sh

# 或者使用Make命令
make docker-compose-up
```

#### 2.1.4 验证部署
```bash
# 检查服务状态
curl http://localhost:8000/health

# 访问前端界面
open http://localhost:7860

# 访问API文档
open http://localhost:8000/docs

# 访问Celery监控
open http://localhost:5555
```

### 2.2 使用Docker Compose

#### 2.2.1 基础部署
```bash
# 启动所有服务
docker-compose -f docker-compose.enhanced.yml up -d

# 查看服务状态
docker-compose -f docker-compose.enhanced.yml ps

# 查看日志
docker-compose -f docker-compose.enhanced.yml logs -f
```

#### 2.2.2 服务管理
```bash
# 停止服务
docker-compose -f docker-compose.enhanced.yml down

# 重启特定服务
docker-compose -f docker-compose.enhanced.yml restart backend

# 扩展Worker数量
docker-compose -f docker-compose.enhanced.yml up -d --scale celery-worker=3
```

## 3. 生产环境部署

### 3.1 生产环境架构

```mermaid
graph TB
    subgraph "负载均衡层"
        LB[Nginx负载均衡器]
        SSL[SSL终端]
    end
    
    subgraph "应用层"
        API1[后端API-1]
        API2[后端API-2]
        API3[后端API-3]
        WORKER1[Celery Worker-1]
        WORKER2[Celery Worker-2]
        WORKER3[Celery Worker-3]
        BEAT[Celery Beat]
        FLOWER[Flower监控]
    end
    
    subgraph "数据层"
        PG_MASTER[(PostgreSQL主库)]
        PG_SLAVE[(PostgreSQL从库)]
        REDIS_MASTER[(Redis主节点)]
        REDIS_SLAVE[(Redis从节点)]
    end
    
    subgraph "存储层"
        NFS[共享文件存储]
        BACKUP[备份存储]
    end
    
    subgraph "监控层"
        PROMETHEUS[Prometheus]
        GRAFANA[Grafana]
        ALERTMANAGER[AlertManager]
    end
    
    LB --> API1
    LB --> API2
    LB --> API3
    
    API1 --> PG_MASTER
    API2 --> PG_MASTER
    API3 --> PG_MASTER
    
    PG_MASTER --> PG_SLAVE
    REDIS_MASTER --> REDIS_SLAVE
    
    WORKER1 --> PG_MASTER
    WORKER2 --> PG_MASTER
    WORKER3 --> PG_MASTER
    
    API1 --> REDIS_MASTER
    WORKER1 --> REDIS_MASTER
    
    API1 --> NFS
    WORKER1 --> NFS
    
    PROMETHEUS --> API1
    PROMETHEUS --> WORKER1
    GRAFANA --> PROMETHEUS
    ALERTMANAGER --> PROMETHEUS
```

### 3.2 生产环境配置

#### 3.2.1 环境变量配置
```bash
# 创建生产环境配置文件
cat > .env.prod << EOF
# 数据库配置
DATABASE_URL=postgresql+asyncpg://ai_bidding:secure_password@postgres-master:5432/ai_bidding
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30

# Redis配置
REDIS_URL=redis://redis-master:6379/0
REDIS_POOL_SIZE=10

# Celery配置
CELERY_BROKER_URL=redis://redis-master:6379/0
CELERY_RESULT_BACKEND=redis://redis-master:6379/0
CELERY_WORKER_CONCURRENCY=4

# 安全配置
JWT_SECRET=your-super-secret-jwt-key
ENCRYPTION_KEY=your-encryption-key

# 日志配置
LOG_LEVEL=INFO
LOG_FORMAT=json

# 监控配置
PROMETHEUS_ENABLED=true
METRICS_PORT=9090

# 文件存储配置
UPLOAD_PATH=/shared/uploads
OUTPUT_PATH=/shared/outputs
MAX_FILE_SIZE=52428800  # 50MB

# LLM配置
LLM_PROVIDER=deepseek
LLM_API_KEY=your-llm-api-key
LLM_MODEL=deepseek-chat
LLM_TIMEOUT=300
LLM_MAX_RETRIES=3
EOF
```

#### 3.2.2 Docker Compose生产配置
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  postgres-master:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ai_bidding
      POSTGRES_USER: ai_bidding
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./postgresql.conf:/etc/postgresql/postgresql.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    networks:
      - ai-bidding-network
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'

  redis-master:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_master_data:/data
    networks:
      - ai-bidding-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

  backend:
    image: ai-bidding:${VERSION}
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
    volumes:
      - shared_storage:/shared
    networks:
      - ai-bidding-network
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 2G
          cpus: '1'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  celery-worker:
    image: ai-bidding:${VERSION}
    command: celery -A backend.tasks.celery_app worker --loglevel=info --concurrency=4
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
    volumes:
      - shared_storage:/shared
    networks:
      - ai-bidding-network
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 4G
          cpus: '2'

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - shared_storage:/var/www/shared
    networks:
      - ai-bidding-network
    depends_on:
      - backend

volumes:
  postgres_master_data:
  redis_master_data:
  shared_storage:
    driver: local
    driver_opts:
      type: nfs
      o: addr=nfs-server,rw
      device: ":/shared/ai-bidding"

networks:
  ai-bidding-network:
    driver: overlay
    attachable: true
```

### 3.3 Nginx生产配置

#### 3.3.1 负载均衡配置
```nginx
# nginx.prod.conf
upstream backend_servers {
    least_conn;
    server backend_1:8000 max_fails=3 fail_timeout=30s;
    server backend_2:8000 max_fails=3 fail_timeout=30s;
    server backend_3:8000 max_fails=3 fail_timeout=30s;
}

upstream frontend_servers {
    server frontend_1:7860;
    server frontend_2:7860;
}

# HTTP重定向到HTTPS
server {
    listen 80;
    server_name ai-bidding.example.com;
    return 301 https://$server_name$request_uri;
}

# HTTPS主配置
server {
    listen 443 ssl http2;
    server_name ai-bidding.example.com;

    # SSL配置
    ssl_certificate /etc/nginx/ssl/ai-bidding.crt;
    ssl_certificate_key /etc/nginx/ssl/ai-bidding.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;

    # 安全头
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";

    # API代理
    location /api/ {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 超时配置
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 300s;
        
        # 缓冲配置
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }

    # 前端代理
    location / {
        proxy_pass http://frontend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # 静态文件服务
    location /uploads/ {
        alias /var/www/shared/uploads/;
        expires 1d;
        add_header Cache-Control "public, immutable";
    }

    location /outputs/ {
        alias /var/www/shared/outputs/;
        expires 1h;
        add_header Cache-Control "public";
    }

    # 健康检查
    location /health {
        proxy_pass http://backend_servers/health;
        access_log off;
    }

    # 监控端点
    location /metrics {
        proxy_pass http://backend_servers/metrics;
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
    }
}
```

### 3.4 数据库优化配置

#### 3.4.1 PostgreSQL配置
```ini
# postgresql.conf
# 连接配置
max_connections = 200
shared_buffers = 4GB
effective_cache_size = 12GB
work_mem = 64MB
maintenance_work_mem = 512MB

# WAL配置
wal_buffers = 16MB
checkpoint_completion_target = 0.9
wal_writer_delay = 200ms

# 查询优化
random_page_cost = 1.1
effective_io_concurrency = 200

# 日志配置
log_destination = 'stderr'
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_min_duration_statement = 1000
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on

# 监控配置
shared_preload_libraries = 'pg_stat_statements'
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all
```

#### 3.4.2 Redis配置
```ini
# redis.conf
# 内存配置
maxmemory 2gb
maxmemory-policy allkeys-lru

# 持久化配置
save 900 1
save 300 10
save 60 10000
appendonly yes
appendfsync everysec

# 网络配置
tcp-keepalive 300
timeout 0

# 安全配置
requirepass your-redis-password
rename-command FLUSHDB ""
rename-command FLUSHALL ""
rename-command DEBUG ""

# 日志配置
loglevel notice
logfile /var/log/redis/redis-server.log
```

## 4. 配置管理

### 4.1 配置文件结构
```
config/
├── config.toml              # 主配置文件
├── environments/            # 环境特定配置
│   ├── development.toml     # 开发环境
│   ├── testing.toml         # 测试环境
│   └── production.toml      # 生产环境
├── secrets/                 # 敏感信息配置
│   ├── api-keys.toml        # API密钥
│   └── database.toml        # 数据库密码
└── templates/               # 配置模板
    └── config.toml.example  # 配置示例
```

### 4.2 配置管理最佳实践

#### 4.2.1 环境变量优先级
1. 环境变量
2. 命令行参数
3. 配置文件
4. 默认值

#### 4.2.2 敏感信息管理
```bash
# 使用环境变量存储敏感信息
export DATABASE_PASSWORD="secure_password"
export JWT_SECRET="super_secret_key"
export LLM_API_KEY="your_api_key"

# 或使用密钥管理服务
# AWS Secrets Manager
# Azure Key Vault
# HashiCorp Vault
```

### 4.3 配置验证
```python
# backend/core/config_validator.py
from pydantic import BaseSettings, validator

class Settings(BaseSettings):
    database_url: str
    redis_url: str
    jwt_secret: str
    llm_api_key: str
    
    @validator('database_url')
    def validate_database_url(cls, v):
        if not v.startswith(('postgresql://', 'postgresql+asyncpg://')):
            raise ValueError('Invalid database URL')
        return v
    
    @validator('jwt_secret')
    def validate_jwt_secret(cls, v):
        if len(v) < 32:
            raise ValueError('JWT secret must be at least 32 characters')
        return v
    
    class Config:
        env_file = '.env'
        case_sensitive = False
```

## 5. 监控告警

### 5.1 Prometheus监控配置

#### 5.1.1 Prometheus配置
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'ai-bidding-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'ai-bidding-celery'
    static_configs:
      - targets: ['flower:5555']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

#### 5.1.2 告警规则
```yaml
# alert_rules.yml
groups:
  - name: ai-bidding-alerts
    rules:
      # 服务可用性告警
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "{{ $labels.instance }} has been down for more than 1 minute."

      # API响应时间告警
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High API latency detected"
          description: "95th percentile latency is {{ $value }}s"

      # 任务队列积压告警
      - alert: HighTaskQueueLength
        expr: celery_queue_length > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High task queue length"
          description: "Task queue length is {{ $value }}"

      # 数据库连接告警
      - alert: DatabaseConnectionHigh
        expr: pg_stat_activity_count > 150
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database connections: {{ $value }}"

      # 内存使用告警
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}%"

      # 磁盘空间告警
      - alert: DiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Disk space low"
          description: "Disk usage is {{ $value }}%"
```

### 5.2 Grafana仪表板

#### 5.2.1 系统概览仪表板
- **服务状态**：各服务运行状态
- **请求量**：API请求量和响应时间
- **任务状态**：Celery任务执行状态
- **资源使用**：CPU、内存、磁盘使用率
- **错误率**：系统错误率和异常统计

#### 5.2.2 业务监控仪表板
- **项目统计**：项目创建和完成数量
- **文档处理**：文档上传和解析统计
- **生成效率**：方案生成时间和成功率
- **用户活跃度**：用户访问和使用统计

### 5.3 日志监控

#### 5.3.1 ELK Stack配置
```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

volumes:
  elasticsearch_data:
```

## 6. 日志管理

### 6.1 日志配置

#### 6.1.1 应用日志配置
```python
# backend/core/logging_config.py
import logging
import sys
from pathlib import Path

def setup_logging(log_level: str = "INFO", log_format: str = "text"):
    """配置应用日志"""

    # 创建日志目录
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    # 日志格式
    if log_format == "json":
        formatter = logging.Formatter(
            '{"timestamp": "%(asctime)s", "level": "%(levelname)s", '
            '"module": "%(name)s", "message": "%(message)s"}'
        )
    else:
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

    # 根日志器配置
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level.upper()))

    # 控制台处理器
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)

    # 文件处理器
    file_handler = logging.FileHandler(log_dir / "app.log")
    file_handler.setFormatter(formatter)
    root_logger.addHandler(file_handler)

    # 错误日志处理器
    error_handler = logging.FileHandler(log_dir / "error.log")
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(formatter)
    root_logger.addHandler(error_handler)
```

#### 6.1.2 Logstash配置
```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }

  file {
    path => "/var/log/ai-bidding/*.log"
    start_position => "beginning"
    codec => "json"
  }
}

filter {
  if [fields][service] == "ai-bidding" {
    json {
      source => "message"
    }

    date {
      match => [ "timestamp", "ISO8601" ]
    }

    mutate {
      add_field => { "service" => "ai-bidding" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ai-bidding-%{+YYYY.MM.dd}"
  }

  stdout {
    codec => rubydebug
  }
}
```

### 6.2 日志轮转配置

#### 6.2.1 Logrotate配置
```bash
# /etc/logrotate.d/ai-bidding
/var/log/ai-bidding/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 ai-bidding ai-bidding
    postrotate
        systemctl reload ai-bidding
    endscript
}
```

### 6.3 日志分析

#### 6.3.1 常用查询
```bash
# 查看错误日志
grep "ERROR" /var/log/ai-bidding/app.log | tail -100

# 查看API访问日志
grep "api" /var/log/ai-bidding/app.log | grep "POST\|GET\|PUT\|DELETE"

# 查看任务执行日志
grep "task" /var/log/ai-bidding/app.log | grep "started\|completed\|failed"

# 查看性能日志
grep "duration" /var/log/ai-bidding/app.log | awk '{print $NF}' | sort -n
```

## 7. 备份恢复

### 7.1 数据备份策略

#### 7.1.1 数据库备份
```bash
#!/bin/bash
# backup_database.sh

# 配置
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="ai_bidding"
DB_USER="ai_bidding"
BACKUP_DIR="/backup/database"
RETENTION_DAYS=30

# 创建备份目录
mkdir -p $BACKUP_DIR

# 生成备份文件名
BACKUP_FILE="$BACKUP_DIR/ai_bidding_$(date +%Y%m%d_%H%M%S).sql"

# 执行备份
pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME > $BACKUP_FILE

# 压缩备份文件
gzip $BACKUP_FILE

# 删除过期备份
find $BACKUP_DIR -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete

echo "数据库备份完成: $BACKUP_FILE.gz"
```

#### 7.1.2 文件备份
```bash
#!/bin/bash
# backup_files.sh

# 配置
SOURCE_DIRS=("/app/uploads" "/app/outputs" "/app/config")
BACKUP_DIR="/backup/files"
RETENTION_DAYS=7

# 创建备份目录
mkdir -p $BACKUP_DIR

# 生成备份文件名
BACKUP_FILE="$BACKUP_DIR/files_$(date +%Y%m%d_%H%M%S).tar.gz"

# 执行备份
tar -czf $BACKUP_FILE ${SOURCE_DIRS[@]}

# 删除过期备份
find $BACKUP_DIR -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

echo "文件备份完成: $BACKUP_FILE"
```

### 7.2 自动备份配置

#### 7.2.1 Crontab配置
```bash
# 编辑crontab
crontab -e

# 添加备份任务
# 每天凌晨2点执行数据库备份
0 2 * * * /opt/ai-bidding/scripts/backup_database.sh

# 每天凌晨3点执行文件备份
0 3 * * * /opt/ai-bidding/scripts/backup_files.sh

# 每周日凌晨4点执行完整备份
0 4 * * 0 /opt/ai-bidding/scripts/backup_full.sh
```

### 7.3 数据恢复

#### 7.3.1 数据库恢复
```bash
#!/bin/bash
# restore_database.sh

# 参数检查
if [ $# -ne 1 ]; then
    echo "用法: $0 <backup_file>"
    exit 1
fi

BACKUP_FILE=$1
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="ai_bidding"
DB_USER="ai_bidding"

# 检查备份文件
if [ ! -f "$BACKUP_FILE" ]; then
    echo "备份文件不存在: $BACKUP_FILE"
    exit 1
fi

# 停止应用服务
echo "停止应用服务..."
docker-compose stop backend celery-worker

# 解压备份文件（如果是压缩的）
if [[ $BACKUP_FILE == *.gz ]]; then
    gunzip -c $BACKUP_FILE > /tmp/restore.sql
    RESTORE_FILE="/tmp/restore.sql"
else
    RESTORE_FILE=$BACKUP_FILE
fi

# 删除现有数据库
echo "删除现有数据库..."
dropdb -h $DB_HOST -p $DB_PORT -U $DB_USER $DB_NAME

# 创建新数据库
echo "创建新数据库..."
createdb -h $DB_HOST -p $DB_PORT -U $DB_USER $DB_NAME

# 恢复数据
echo "恢复数据..."
psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME < $RESTORE_FILE

# 清理临时文件
if [ "$RESTORE_FILE" = "/tmp/restore.sql" ]; then
    rm /tmp/restore.sql
fi

# 启动应用服务
echo "启动应用服务..."
docker-compose start backend celery-worker

echo "数据库恢复完成"
```

## 8. 故障排除

### 8.1 常见问题诊断

#### 8.1.1 服务启动失败
```bash
# 检查服务状态
docker-compose ps

# 查看服务日志
docker-compose logs backend
docker-compose logs celery-worker
docker-compose logs postgres
docker-compose logs redis

# 检查端口占用
netstat -tlnp | grep :8000
netstat -tlnp | grep :5432
netstat -tlnp | grep :6379

# 检查磁盘空间
df -h

# 检查内存使用
free -h
```

#### 8.1.2 数据库连接问题
```bash
# 测试数据库连接
psql -h localhost -p 5432 -U ai_bidding -d ai_bidding

# 检查数据库状态
docker exec ai-bidding-postgres pg_isready -U ai_bidding

# 查看数据库日志
docker logs ai-bidding-postgres

# 检查连接数
psql -h localhost -p 5432 -U ai_bidding -d ai_bidding -c "SELECT count(*) FROM pg_stat_activity;"
```

#### 8.1.3 Redis连接问题
```bash
# 测试Redis连接
redis-cli -h localhost -p 6379 ping

# 检查Redis状态
docker exec ai-bidding-redis redis-cli ping

# 查看Redis日志
docker logs ai-bidding-redis

# 检查Redis内存使用
redis-cli -h localhost -p 6379 info memory
```

#### 8.1.4 Celery任务问题
```bash
# 检查Celery Worker状态
docker exec ai-bidding-celery-worker celery -A backend.tasks.celery_app inspect ping

# 查看活跃任务
docker exec ai-bidding-celery-worker celery -A backend.tasks.celery_app inspect active

# 查看任务队列
docker exec ai-bidding-celery-worker celery -A backend.tasks.celery_app inspect reserved

# 清空任务队列
docker exec ai-bidding-celery-worker celery -A backend.tasks.celery_app purge
```

### 8.2 性能问题排查

#### 8.2.1 API响应慢
```bash
# 检查API响应时间
curl -w "@curl-format.txt" -o /dev/null -s "http://localhost:8000/health"

# curl-format.txt内容:
#     time_namelookup:  %{time_namelookup}\n
#        time_connect:  %{time_connect}\n
#     time_appconnect:  %{time_appconnect}\n
#    time_pretransfer:  %{time_pretransfer}\n
#       time_redirect:  %{time_redirect}\n
#  time_starttransfer:  %{time_starttransfer}\n
#                     ----------\n
#          time_total:  %{time_total}\n

# 检查数据库查询性能
psql -h localhost -p 5432 -U ai_bidding -d ai_bidding -c "SELECT query, mean_time, calls FROM pg_stat_statements ORDER BY mean_time DESC LIMIT 10;"

# 检查系统负载
top
htop
iostat -x 1
```

#### 8.2.2 内存泄漏排查
```bash
# 检查容器内存使用
docker stats

# 检查Python进程内存
ps aux | grep python | awk '{print $2, $4, $11}' | sort -k2 -nr

# 使用内存分析工具
pip install memory-profiler
python -m memory_profiler your_script.py
```

### 8.3 故障恢复流程

#### 8.3.1 服务故障恢复
```bash
#!/bin/bash
# service_recovery.sh

echo "开始服务故障恢复..."

# 1. 停止所有服务
echo "停止所有服务..."
docker-compose down

# 2. 清理容器和网络
echo "清理容器和网络..."
docker system prune -f

# 3. 检查磁盘空间
echo "检查磁盘空间..."
df -h

# 4. 重新启动服务
echo "重新启动服务..."
docker-compose up -d

# 5. 等待服务启动
echo "等待服务启动..."
sleep 30

# 6. 健康检查
echo "执行健康检查..."
curl -f http://localhost:8000/health || exit 1

echo "服务恢复完成"
```

#### 8.3.2 数据故障恢复
```bash
#!/bin/bash
# data_recovery.sh

echo "开始数据故障恢复..."

# 1. 停止应用服务
echo "停止应用服务..."
docker-compose stop backend celery-worker

# 2. 检查数据完整性
echo "检查数据完整性..."
docker exec ai-bidding-postgres pg_dump --schema-only ai_bidding > /tmp/schema_check.sql

# 3. 从最新备份恢复
echo "从最新备份恢复..."
LATEST_BACKUP=$(ls -t /backup/database/*.sql.gz | head -1)
./restore_database.sh $LATEST_BACKUP

# 4. 验证数据恢复
echo "验证数据恢复..."
psql -h localhost -p 5432 -U ai_bidding -d ai_bidding -c "SELECT count(*) FROM projects;"

# 5. 重启应用服务
echo "重启应用服务..."
docker-compose start backend celery-worker

echo "数据恢复完成"
```

---

**文档版本**：v2.0
**最后更新**：2025-07-02
**维护人员**：AI投标系统开发团队
