# AI投标方案生成系统 - 技术架构详解

## 📋 目录
- [1. 架构概览](#1-架构概览)
- [2. 服务层架构](#2-服务层架构)
- [3. 数据架构](#3-数据架构)
- [4. 工作流引擎](#4-工作流引擎)
- [5. AI服务架构](#5-ai服务架构)
- [6. 部署架构](#6-部署架构)
- [7. 安全架构](#7-安全架构)

## 1. 架构概览

### 1.1 整体架构图

```mermaid
graph TB
    subgraph "用户层"
        UI[Web界面<br/>Gradio]
        API[API客户端]
    end
    
    subgraph "接入层"
        NGINX[Nginx<br/>反向代理]
        LB[负载均衡]
    end
    
    subgraph "应用层"
        BACKEND[后端服务<br/>FastAPI]
        FRONTEND[前端服务<br/>Gradio]
        WORKER[异步任务<br/>Celery Worker]
        BEAT[定时任务<br/>Celery Beat]
        FLOWER[任务监控<br/>Flower]
    end
    
    subgraph "业务层"
        WF[工作流引擎<br/>LangGraph]
        LLM[AI服务<br/>LangChain]
        DOC[文档处理<br/>Unstructured]
        VAL[校验服务]
        OUT[输出解析器]
    end
    
    subgraph "数据层"
        PG[(PostgreSQL<br/>主数据库)]
        REDIS[(Redis<br/>缓存/队列)]
        FILES[文件存储<br/>本地/云存储]
    end
    
    UI --> NGINX
    API --> NGINX
    NGINX --> BACKEND
    NGINX --> FRONTEND
    NGINX --> FLOWER
    
    BACKEND --> WF
    WORKER --> WF
    WF --> LLM
    WF --> DOC
    WF --> VAL
    WF --> OUT
    
    BACKEND --> PG
    BACKEND --> REDIS
    WORKER --> PG
    WORKER --> REDIS
    BEAT --> REDIS
    
    DOC --> FILES
    OUT --> FILES
```

### 1.2 技术栈选型

| 层级 | 技术选择 | 版本 | 选择理由 |
|------|----------|------|----------|
| **前端** | Gradio | 4.0+ | 快速原型开发，AI应用友好 |
| **后端** | FastAPI | 0.115+ | 高性能异步框架，自动API文档 |
| **工作流** | LangGraph | 0.4+ | 状态管理，可视化工作流 |
| **AI框架** | LangChain | 0.3+ | 丰富的LLM集成，生态完善 |
| **任务队列** | Celery | 5.3+ | 成熟的分布式任务队列 |
| **数据库** | PostgreSQL | 15+ | 可靠的关系型数据库 |
| **缓存** | Redis | 7+ | 高性能内存数据库 |
| **容器化** | Docker | 20+ | 标准化部署，环境一致性 |

### 1.3 架构特点

#### 1.3.1 微服务架构
- **服务拆分**：按业务功能拆分为独立服务
- **独立部署**：每个服务可独立部署和扩展
- **技术异构**：不同服务可使用不同技术栈

#### 1.3.2 异步处理
- **任务队列**：长时间任务异步处理
- **事件驱动**：基于事件的松耦合架构
- **并发处理**：支持高并发请求

#### 1.3.3 状态管理
- **工作流状态**：LangGraph管理复杂业务流程
- **检查点机制**：支持流程中断和恢复
- **状态持久化**：状态数据持久化存储

## 2. 服务层架构

### 2.1 后端API服务 (FastAPI)

#### 2.1.1 服务结构
```
backend/
├── api/                 # API路由层
│   ├── routes/         # 路由定义
│   │   ├── projects.py # 项目管理API
│   │   ├── documents.py# 文档管理API
│   │   ├── tasks.py    # 任务管理API
│   │   └── generation.py# 生成服务API
├── core/               # 核心配置
│   ├── database.py     # 数据库配置
│   ├── toml_config.py  # 配置管理
│   └── security.py     # 安全配置
├── models/             # 数据模型
├── schemas/            # API模式
├── services/           # 业务服务
└── main.py            # 应用入口
```

#### 2.1.2 API设计原则
- **RESTful设计**：遵循REST架构风格
- **版本控制**：API版本管理策略
- **错误处理**：统一的错误响应格式
- **文档自动生成**：基于OpenAPI的自动文档

#### 2.1.3 中间件配置
```python
# CORS中间件
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 请求日志中间件
app.add_middleware(RequestLoggingMiddleware)

# 异常处理中间件
app.add_middleware(ExceptionHandlingMiddleware)
```

### 2.2 前端服务 (Gradio)

#### 2.2.1 界面组件
- **项目管理**：项目创建、列表、详情
- **文档上传**：支持拖拽上传，进度显示
- **任务监控**：实时任务状态和进度
- **结果展示**：生成结果预览和下载

#### 2.2.2 交互设计
```python
class AIBiddingApp:
    def __init__(self):
        self.current_project_id = None
        self.current_task_id = None
    
    def create_interface(self):
        with gr.Blocks() as interface:
            # 项目管理界面
            with gr.Tab("项目管理"):
                self.create_project_tab()
            
            # 任务监控界面
            with gr.Tab("任务监控"):
                self.create_task_tab()
            
            # 结果查看界面
            with gr.Tab("结果查看"):
                self.create_result_tab()
        
        return interface
```

### 2.3 异步任务服务 (Celery)

#### 2.3.1 任务类型
```python
class TaskType(str, Enum):
    FULL_WORKFLOW = "full_workflow"           # 完整工作流
    PARSE_DOCUMENT = "parse_document"         # 文档解析
    ANALYZE_REQUIREMENTS = "analyze_requirements"  # 需求分析
    GENERATE_OUTLINE = "generate_outline"     # 生成提纲
    GENERATE_CONTENT = "generate_content"     # 生成内容
    DIFFERENTIATE_CONTENT = "differentiate_content"  # 差异化处理
    VALIDATE_CONTENT = "validate_content"     # 内容校验
    GENERATE_DOCUMENT = "generate_document"   # 生成文档
```

#### 2.3.2 任务配置
```python
# Celery配置
celery_app = Celery(
    "ai_bidding",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/0",
    include=["backend.tasks.workflow_tasks"]
)

# 任务路由配置
celery_app.conf.task_routes = {
    'backend.tasks.workflow_tasks.run_full_workflow': {'queue': 'workflow_high'},
    'backend.tasks.workflow_tasks.*': {'queue': 'workflow'},
    '*': {'queue': 'default'},
}
```

#### 2.3.3 重试策略
```python
@task_with_retry(
    bind=True,
    autoretry_for=(Exception,),
    retry_backoff=exponential_backoff,
    retry_kwargs={'max_retries': 3},
    retry_jitter=True
)
def run_full_workflow(self, task_id: str, project_id: str, document_path: str, config: Dict[str, Any]):
    # 任务实现
    pass
```

## 3. 数据架构

### 3.1 数据库设计

#### 3.1.1 主数据库 (PostgreSQL)
```sql
-- 项目表
CREATE TABLE projects (
    id VARCHAR PRIMARY KEY,
    name VARCHAR NOT NULL,
    description TEXT,
    status VARCHAR DEFAULT 'created',
    document_path VARCHAR,
    document_name VARCHAR,
    requirements_analysis TEXT,
    outline TEXT,
    sections JSON DEFAULT '[]',
    final_document_path VARCHAR,
    enable_differentiation BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 任务表
CREATE TABLE tasks (
    id VARCHAR PRIMARY KEY,
    project_id VARCHAR REFERENCES projects(id),
    task_type VARCHAR NOT NULL,
    status VARCHAR DEFAULT 'pending',
    config JSON DEFAULT '{}',
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    result JSON,
    error_message TEXT,
    error_traceback TEXT,
    progress INTEGER DEFAULT 0,
    current_step VARCHAR,
    total_steps INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 任务检查点表
CREATE TABLE task_checkpoints (
    id VARCHAR PRIMARY KEY,
    task_id VARCHAR REFERENCES tasks(id),
    step_name VARCHAR NOT NULL,
    step_order INTEGER NOT NULL,
    state_data JSON NOT NULL,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    duration_seconds INTEGER,
    is_completed BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.1.2 索引设计
```sql
-- 性能优化索引
CREATE INDEX idx_projects_status ON projects(status);
CREATE INDEX idx_projects_created_at ON projects(created_at);
CREATE INDEX idx_tasks_project_id ON tasks(project_id);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_created_at ON tasks(created_at);
CREATE INDEX idx_checkpoints_task_id ON task_checkpoints(task_id);
CREATE INDEX idx_checkpoints_step_order ON task_checkpoints(step_order);
```

### 3.2 缓存架构 (Redis)

#### 3.2.1 缓存策略
```python
# 缓存配置
CACHE_CONFIG = {
    "task_status": {"ttl": 300},      # 任务状态缓存5分钟
    "project_info": {"ttl": 1800},    # 项目信息缓存30分钟
    "llm_response": {"ttl": 3600},    # LLM响应缓存1小时
    "document_content": {"ttl": 7200}, # 文档内容缓存2小时
}
```

#### 3.2.2 数据结构
```
Redis数据结构：
├── task:{task_id}:status          # 任务状态 (String)
├── task:{task_id}:progress        # 任务进度 (String)
├── project:{project_id}:info      # 项目信息 (Hash)
├── llm:cache:{hash}               # LLM响应缓存 (String)
├── celery:*                       # Celery队列数据
└── session:{session_id}           # 用户会话 (Hash)
```

### 3.3 文件存储架构

#### 3.3.1 目录结构
```
storage/
├── uploads/                    # 上传文件
│   ├── documents/             # 招标文档
│   └── temp/                  # 临时文件
├── outputs/                   # 输出文件
│   ├── proposals/             # 生成的方案
│   └── reports/               # 分析报告
└── logs/                      # 日志文件
    ├── app.log               # 应用日志
    ├── celery.log            # Celery日志
    └── error.log             # 错误日志
```

#### 3.3.2 文件管理策略
- **命名规范**：时间戳 + 项目ID + 文件类型
- **清理策略**：定期清理过期临时文件
- **备份策略**：重要文件自动备份
- **访问控制**：基于项目的文件访问权限

## 4. 工作流引擎

### 4.1 LangGraph工作流设计

#### 4.1.1 工作流节点
```python
class WorkflowEngine:
    def _build_workflow(self) -> CompiledStateGraph:
        workflow = StateGraph(WorkflowState)
        
        # 添加节点
        workflow.add_node("parse_document", self._parse_document)
        workflow.add_node("analyze_requirements", self._analyze_requirements)
        workflow.add_node("validate_requirements", self._validate_requirements)
        workflow.add_node("generate_outline", self._generate_outline)
        workflow.add_node("validate_outline", self._validate_outline)
        workflow.add_node("generate_content", self._generate_content)
        workflow.add_node("validate_content", self._validate_content)
        workflow.add_node("differentiate_content", self._differentiate_content)
        workflow.add_node("finalize", self._finalize)
        
        # 设置流程
        workflow.set_entry_point("parse_document")
        workflow.add_edge("parse_document", "analyze_requirements")
        # ... 更多边的定义
        
        return workflow.compile()
```

#### 4.1.2 状态管理
```python
class WorkflowState(BaseModel):
    project_id: str
    current_step: str
    document_content: Optional[str] = None
    requirements_analysis: Optional[str] = None
    outline: Optional[str] = None
    sections: List[Dict[str, Any]] = Field(default_factory=list)
    enable_differentiation: bool = True
    enable_validation: bool = True
    task_id: Optional[str] = None
    validation_reports: List[Dict[str, Any]] = Field(default_factory=list)
    error: Optional[str] = None
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
```

#### 4.1.3 检查点机制
```python
async def save_checkpoint(self, task_id: str, step_name: str, state: WorkflowState):
    """保存工作流检查点"""
    checkpoint_data = TaskCheckpointCreate(
        task_id=task_id,
        step_name=step_name,
        step_order=self.get_step_order(step_name),
        state_data=state.model_dump()
    )
    
    await persistence_service.create_checkpoint(checkpoint_data)
    logger.info(f"检查点已保存: {task_id} - {step_name}")
```

### 4.2 错误处理和恢复

#### 4.2.1 错误分类
```python
class WorkflowError(Exception):
    """工作流错误基类"""
    pass

class DocumentParseError(WorkflowError):
    """文档解析错误"""
    pass

class LLMServiceError(WorkflowError):
    """LLM服务错误"""
    pass

class ValidationError(WorkflowError):
    """校验错误"""
    pass
```

#### 4.2.2 恢复策略
```python
async def recover_from_checkpoint(self, task_id: str) -> WorkflowState:
    """从检查点恢复工作流"""
    latest_checkpoint = await persistence_service.get_latest_checkpoint(task_id)
    
    if latest_checkpoint:
        state = WorkflowState(**latest_checkpoint.state_data)
        logger.info(f"从检查点恢复: {task_id} - {latest_checkpoint.step_name}")
        return state
    else:
        raise ValueError(f"未找到任务检查点: {task_id}")
```

## 5. AI服务架构

### 5.1 LLM服务设计

#### 5.1.1 多提供商支持
```python
class LLMService:
    def __init__(self):
        self.provider = toml_config.llm.provider
        self.llm = self._create_llm_client()
    
    def _create_llm_client(self):
        if self.provider == "deepseek":
            return ChatDeepSeek(
                model=toml_config.llm.model_name,
                api_key=toml_config.llm.api_key,
                temperature=0.7,
                max_tokens=4000
            )
        elif self.provider == "openai":
            return ChatOpenAI(
                model=toml_config.llm.model_name,
                api_key=toml_config.llm.api_key
            )
        # 支持更多提供商...
```

#### 5.1.2 Prompt工程
```python
class PromptTemplates:
    REQUIREMENT_ANALYSIS = """
    你是一位资深的投标专家，精通招投标业务。请分析以下招标文档，提取关键需求信息。
    
    请按照以下结构输出分析结果：
    1. 技术需求：列出所有技术要求和规格
    2. 功能需求：列出系统功能要求
    3. 性能指标：列出性能相关要求
    4. 资质要求：列出投标人资质要求
    5. 评分标准：列出评分标准和权重
    6. 关键风险点：标记可能的风险点
    
    请确保：
    - 不遗漏任何强制性要求
    - 准确理解技术术语
    - 标记重要程度（高/中/低）
    """
    
    OUTLINE_GENERATION = """
    你是一位资深的技术方案架构师。请根据需求分析结果，生成专业的投标技术方案提纲。
    
    提纲要求：
    1. 结构清晰，层次分明
    2. 覆盖所有需求点
    3. 逻辑合理，符合投标规范
    4. 突出技术优势和创新点
    """
```

#### 5.1.3 响应处理
```python
async def _call_llm_with_prompt(self, prompt: str, **kwargs) -> str:
    """调用LLM并处理响应"""
    try:
        messages = [HumanMessage(content=prompt)]
        response = await self.llm.ainvoke(messages, **kwargs)
        return response.content
    except Exception as e:
        logger.error(f"LLM调用失败: {e}")
        raise LLMServiceError(f"LLM服务调用失败: {str(e)}")
```

### 5.2 文档处理服务

#### 5.2.1 解析器配置
```python
class DocumentParser:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", ".", "。", "!", "?", " "]
        )
    
    def parse_document(self, file_path: Path) -> Dict[str, Any]:
        loader = UnstructuredLoader(
            file_path=str(file_path),
            languages=["chi_sim", "eng"],
            strategy="fast"
        )
        documents = loader.load()
        chunks = self.text_splitter.split_documents(documents)
        
        return {
            "file_name": file_path.name,
            "file_type": file_path.suffix,
            "documents": documents,
            "chunks": chunks,
            "metadata": {
                "total_pages": len(documents),
                "total_chunks": len(chunks),
            }
        }
```

### 5.3 校验服务

#### 5.3.1 校验规则
```python
class ValidationService:
    async def validate_requirements_analysis(self, analysis: str, original_document: str) -> List[ValidationIssue]:
        """校验需求分析的完整性和准确性"""
        issues = []
        
        # 基础校验
        if len(analysis) < 100:
            issues.append(ValidationIssue(
                level=ValidationLevel.HIGH,
                result=ValidationResult.ERROR,
                message="需求分析内容过短，可能不够详细",
                suggestion="请补充更详细的需求分析"
            ))
        
        # LLM校验
        validation_result = await self._llm_validate_completeness(analysis, original_document)
        issues.extend(validation_result)
        
        return issues
```

## 6. 部署架构

### 6.1 容器化部署

#### 6.1.1 Docker配置
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 安装Python依赖
COPY pyproject.toml uv.lock ./
RUN pip install uv && uv sync --frozen

# 复制应用代码
COPY . .

# 设置环境变量
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# 暴露端口
EXPOSE 8000 7860

# 启动命令
CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 6.1.2 Docker Compose配置
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ai_bidding
      POSTGRES_USER: ai_bidding
      POSTGRES_PASSWORD: ai_bidding_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_bidding"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://ai_bidding:ai_bidding_password@postgres:5432/ai_bidding
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
```

### 6.2 生产环境部署

#### 6.2.1 负载均衡配置
```nginx
upstream backend_servers {
    server backend1:8000;
    server backend2:8000;
    server backend3:8000;
}

server {
    listen 80;
    server_name ai-bidding.example.com;
    
    location /api/ {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    
    location / {
        proxy_pass http://frontend:7860;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

#### 6.2.2 监控配置
```yaml
# Prometheus配置
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'ai-bidding-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    
  - job_name: 'ai-bidding-celery'
    static_configs:
      - targets: ['flower:5555']
    metrics_path: '/metrics'
```

## 7. 安全架构

### 7.1 数据安全

#### 7.1.1 数据加密
- **传输加密**：HTTPS/TLS 1.3
- **存储加密**：数据库字段级加密
- **文件加密**：敏感文件AES-256加密

#### 7.1.2 访问控制
```python
class SecurityService:
    def __init__(self):
        self.jwt_secret = os.getenv("JWT_SECRET")
        self.algorithm = "HS256"
    
    def create_access_token(self, data: dict, expires_delta: timedelta = None):
        to_encode = data.copy()
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=15)
        
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, self.jwt_secret, algorithm=self.algorithm)
        return encoded_jwt
```

### 7.2 API安全

#### 7.2.1 认证授权
- **JWT Token**：基于JWT的无状态认证
- **角色权限**：基于角色的访问控制(RBAC)
- **API限流**：防止API滥用

#### 7.2.2 输入验证
```python
class DocumentUploadRequest(BaseModel):
    file: UploadFile = Field(..., description="上传文件")
    
    @validator('file')
    def validate_file(cls, v):
        # 文件类型检查
        allowed_types = ['.pdf', '.docx', '.doc']
        if not any(v.filename.endswith(ext) for ext in allowed_types):
            raise ValueError('不支持的文件类型')
        
        # 文件大小检查
        if v.size > 50 * 1024 * 1024:  # 50MB
            raise ValueError('文件大小超过限制')
        
        return v
```

### 7.3 运行时安全

#### 7.3.1 容器安全
- **最小权限原则**：容器以非root用户运行
- **镜像扫描**：定期扫描容器镜像漏洞
- **网络隔离**：容器网络隔离

#### 7.3.2 日志审计
```python
class AuditLogger:
    def __init__(self):
        self.logger = logging.getLogger("audit")
    
    def log_api_access(self, user_id: str, endpoint: str, method: str, status: int):
        self.logger.info(
            f"API访问 - 用户:{user_id} 端点:{endpoint} 方法:{method} 状态:{status}",
            extra={
                "user_id": user_id,
                "endpoint": endpoint,
                "method": method,
                "status": status,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
```

---

**文档版本**：v2.0  
**最后更新**：2025-07-02  
**维护人员**：AI投标系统开发团队
