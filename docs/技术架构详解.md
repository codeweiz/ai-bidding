# AIæŠ•æ ‡æ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿ - æŠ€æœ¯æ¶æ„è¯¦è§£

## ğŸ“‹ ç›®å½•
- [1. æ¶æ„æ¦‚è§ˆ](#1-æ¶æ„æ¦‚è§ˆ)
- [2. æœåŠ¡å±‚æ¶æ„](#2-æœåŠ¡å±‚æ¶æ„)
- [3. æ•°æ®æ¶æ„](#3-æ•°æ®æ¶æ„)
- [4. å·¥ä½œæµå¼•æ“](#4-å·¥ä½œæµå¼•æ“)
- [5. AIæœåŠ¡æ¶æ„](#5-aiæœåŠ¡æ¶æ„)
- [6. éƒ¨ç½²æ¶æ„](#6-éƒ¨ç½²æ¶æ„)
- [7. å®‰å…¨æ¶æ„](#7-å®‰å…¨æ¶æ„)

## 1. æ¶æ„æ¦‚è§ˆ

### 1.1 æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ç”¨æˆ·å±‚"
        UI[Webç•Œé¢<br/>Gradio]
        API[APIå®¢æˆ·ç«¯]
    end
    
    subgraph "æ¥å…¥å±‚"
        NGINX[Nginx<br/>åå‘ä»£ç†]
        LB[è´Ÿè½½å‡è¡¡]
    end
    
    subgraph "åº”ç”¨å±‚"
        BACKEND[åç«¯æœåŠ¡<br/>FastAPI]
        FRONTEND[å‰ç«¯æœåŠ¡<br/>Gradio]
        WORKER[å¼‚æ­¥ä»»åŠ¡<br/>Celery Worker]
        BEAT[å®šæ—¶ä»»åŠ¡<br/>Celery Beat]
        FLOWER[ä»»åŠ¡ç›‘æ§<br/>Flower]
    end
    
    subgraph "ä¸šåŠ¡å±‚"
        WF[å·¥ä½œæµå¼•æ“<br/>LangGraph]
        LLM[AIæœåŠ¡<br/>LangChain]
        DOC[æ–‡æ¡£å¤„ç†<br/>Unstructured]
        VAL[æ ¡éªŒæœåŠ¡]
        OUT[è¾“å‡ºè§£æå™¨]
    end
    
    subgraph "æ•°æ®å±‚"
        PG[(PostgreSQL<br/>ä¸»æ•°æ®åº“)]
        REDIS[(Redis<br/>ç¼“å­˜/é˜Ÿåˆ—)]
        FILES[æ–‡ä»¶å­˜å‚¨<br/>æœ¬åœ°/äº‘å­˜å‚¨]
    end
    
    UI --> NGINX
    API --> NGINX
    NGINX --> BACKEND
    NGINX --> FRONTEND
    NGINX --> FLOWER
    
    BACKEND --> WF
    WORKER --> WF
    WF --> LLM
    WF --> DOC
    WF --> VAL
    WF --> OUT
    
    BACKEND --> PG
    BACKEND --> REDIS
    WORKER --> PG
    WORKER --> REDIS
    BEAT --> REDIS
    
    DOC --> FILES
    OUT --> FILES
```

### 1.2 æŠ€æœ¯æ ˆé€‰å‹

| å±‚çº§ | æŠ€æœ¯é€‰æ‹© | ç‰ˆæœ¬ | é€‰æ‹©ç†ç”± |
|------|----------|------|----------|
| **å‰ç«¯** | Gradio | 4.0+ | å¿«é€ŸåŸå‹å¼€å‘ï¼ŒAIåº”ç”¨å‹å¥½ |
| **åç«¯** | FastAPI | 0.115+ | é«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶ï¼Œè‡ªåŠ¨APIæ–‡æ¡£ |
| **å·¥ä½œæµ** | LangGraph | 0.4+ | çŠ¶æ€ç®¡ç†ï¼Œå¯è§†åŒ–å·¥ä½œæµ |
| **AIæ¡†æ¶** | LangChain | 0.3+ | ä¸°å¯Œçš„LLMé›†æˆï¼Œç”Ÿæ€å®Œå–„ |
| **ä»»åŠ¡é˜Ÿåˆ—** | Celery | 5.3+ | æˆç†Ÿçš„åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ— |
| **æ•°æ®åº“** | PostgreSQL | 15+ | å¯é çš„å…³ç³»å‹æ•°æ®åº“ |
| **ç¼“å­˜** | Redis | 7+ | é«˜æ€§èƒ½å†…å­˜æ•°æ®åº“ |
| **å®¹å™¨åŒ–** | Docker | 20+ | æ ‡å‡†åŒ–éƒ¨ç½²ï¼Œç¯å¢ƒä¸€è‡´æ€§ |

### 1.3 æ¶æ„ç‰¹ç‚¹

#### 1.3.1 å¾®æœåŠ¡æ¶æ„
- **æœåŠ¡æ‹†åˆ†**ï¼šæŒ‰ä¸šåŠ¡åŠŸèƒ½æ‹†åˆ†ä¸ºç‹¬ç«‹æœåŠ¡
- **ç‹¬ç«‹éƒ¨ç½²**ï¼šæ¯ä¸ªæœåŠ¡å¯ç‹¬ç«‹éƒ¨ç½²å’Œæ‰©å±•
- **æŠ€æœ¯å¼‚æ„**ï¼šä¸åŒæœåŠ¡å¯ä½¿ç”¨ä¸åŒæŠ€æœ¯æ ˆ

#### 1.3.2 å¼‚æ­¥å¤„ç†
- **ä»»åŠ¡é˜Ÿåˆ—**ï¼šé•¿æ—¶é—´ä»»åŠ¡å¼‚æ­¥å¤„ç†
- **äº‹ä»¶é©±åŠ¨**ï¼šåŸºäºäº‹ä»¶çš„æ¾è€¦åˆæ¶æ„
- **å¹¶å‘å¤„ç†**ï¼šæ”¯æŒé«˜å¹¶å‘è¯·æ±‚

#### 1.3.3 çŠ¶æ€ç®¡ç†
- **å·¥ä½œæµçŠ¶æ€**ï¼šLangGraphç®¡ç†å¤æ‚ä¸šåŠ¡æµç¨‹
- **æ£€æŸ¥ç‚¹æœºåˆ¶**ï¼šæ”¯æŒæµç¨‹ä¸­æ–­å’Œæ¢å¤
- **çŠ¶æ€æŒä¹…åŒ–**ï¼šçŠ¶æ€æ•°æ®æŒä¹…åŒ–å­˜å‚¨

## 2. æœåŠ¡å±‚æ¶æ„

### 2.1 åç«¯APIæœåŠ¡ (FastAPI)

#### 2.1.1 æœåŠ¡ç»“æ„
```
backend/
â”œâ”€â”€ api/                 # APIè·¯ç”±å±‚
â”‚   â”œâ”€â”€ routes/         # è·¯ç”±å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ projects.py # é¡¹ç›®ç®¡ç†API
â”‚   â”‚   â”œâ”€â”€ documents.py# æ–‡æ¡£ç®¡ç†API
â”‚   â”‚   â”œâ”€â”€ tasks.py    # ä»»åŠ¡ç®¡ç†API
â”‚   â”‚   â””â”€â”€ generation.py# ç”ŸæˆæœåŠ¡API
â”œâ”€â”€ core/               # æ ¸å¿ƒé…ç½®
â”‚   â”œâ”€â”€ database.py     # æ•°æ®åº“é…ç½®
â”‚   â”œâ”€â”€ toml_config.py  # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ security.py     # å®‰å…¨é…ç½®
â”œâ”€â”€ models/             # æ•°æ®æ¨¡å‹
â”œâ”€â”€ schemas/            # APIæ¨¡å¼
â”œâ”€â”€ services/           # ä¸šåŠ¡æœåŠ¡
â””â”€â”€ main.py            # åº”ç”¨å…¥å£
```

#### 2.1.2 APIè®¾è®¡åŸåˆ™
- **RESTfulè®¾è®¡**ï¼šéµå¾ªRESTæ¶æ„é£æ ¼
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šAPIç‰ˆæœ¬ç®¡ç†ç­–ç•¥
- **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€çš„é”™è¯¯å“åº”æ ¼å¼
- **æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ**ï¼šåŸºäºOpenAPIçš„è‡ªåŠ¨æ–‡æ¡£

#### 2.1.3 ä¸­é—´ä»¶é…ç½®
```python
# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
app.add_middleware(RequestLoggingMiddleware)

# å¼‚å¸¸å¤„ç†ä¸­é—´ä»¶
app.add_middleware(ExceptionHandlingMiddleware)
```

### 2.2 å‰ç«¯æœåŠ¡ (Gradio)

#### 2.2.1 ç•Œé¢ç»„ä»¶
- **é¡¹ç›®ç®¡ç†**ï¼šé¡¹ç›®åˆ›å»ºã€åˆ—è¡¨ã€è¯¦æƒ…
- **æ–‡æ¡£ä¸Šä¼ **ï¼šæ”¯æŒæ‹–æ‹½ä¸Šä¼ ï¼Œè¿›åº¦æ˜¾ç¤º
- **ä»»åŠ¡ç›‘æ§**ï¼šå®æ—¶ä»»åŠ¡çŠ¶æ€å’Œè¿›åº¦
- **ç»“æœå±•ç¤º**ï¼šç”Ÿæˆç»“æœé¢„è§ˆå’Œä¸‹è½½

#### 2.2.2 äº¤äº’è®¾è®¡
```python
class AIBiddingApp:
    def __init__(self):
        self.current_project_id = None
        self.current_task_id = None
    
    def create_interface(self):
        with gr.Blocks() as interface:
            # é¡¹ç›®ç®¡ç†ç•Œé¢
            with gr.Tab("é¡¹ç›®ç®¡ç†"):
                self.create_project_tab()
            
            # ä»»åŠ¡ç›‘æ§ç•Œé¢
            with gr.Tab("ä»»åŠ¡ç›‘æ§"):
                self.create_task_tab()
            
            # ç»“æœæŸ¥çœ‹ç•Œé¢
            with gr.Tab("ç»“æœæŸ¥çœ‹"):
                self.create_result_tab()
        
        return interface
```

### 2.3 å¼‚æ­¥ä»»åŠ¡æœåŠ¡ (Celery)

#### 2.3.1 ä»»åŠ¡ç±»å‹
```python
class TaskType(str, Enum):
    FULL_WORKFLOW = "full_workflow"           # å®Œæ•´å·¥ä½œæµ
    PARSE_DOCUMENT = "parse_document"         # æ–‡æ¡£è§£æ
    ANALYZE_REQUIREMENTS = "analyze_requirements"  # éœ€æ±‚åˆ†æ
    GENERATE_OUTLINE = "generate_outline"     # ç”Ÿæˆæçº²
    GENERATE_CONTENT = "generate_content"     # ç”Ÿæˆå†…å®¹
    DIFFERENTIATE_CONTENT = "differentiate_content"  # å·®å¼‚åŒ–å¤„ç†
    VALIDATE_CONTENT = "validate_content"     # å†…å®¹æ ¡éªŒ
    GENERATE_DOCUMENT = "generate_document"   # ç”Ÿæˆæ–‡æ¡£
```

#### 2.3.2 ä»»åŠ¡é…ç½®
```python
# Celeryé…ç½®
celery_app = Celery(
    "ai_bidding",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/0",
    include=["backend.tasks.workflow_tasks"]
)

# ä»»åŠ¡è·¯ç”±é…ç½®
celery_app.conf.task_routes = {
    'backend.tasks.workflow_tasks.run_full_workflow': {'queue': 'workflow_high'},
    'backend.tasks.workflow_tasks.*': {'queue': 'workflow'},
    '*': {'queue': 'default'},
}
```

#### 2.3.3 é‡è¯•ç­–ç•¥
```python
@task_with_retry(
    bind=True,
    autoretry_for=(Exception,),
    retry_backoff=exponential_backoff,
    retry_kwargs={'max_retries': 3},
    retry_jitter=True
)
def run_full_workflow(self, task_id: str, project_id: str, document_path: str, config: Dict[str, Any]):
    # ä»»åŠ¡å®ç°
    pass
```

## 3. æ•°æ®æ¶æ„

### 3.1 æ•°æ®åº“è®¾è®¡

#### 3.1.1 ä¸»æ•°æ®åº“ (PostgreSQL)
```sql
-- é¡¹ç›®è¡¨
CREATE TABLE projects (
    id VARCHAR PRIMARY KEY,
    name VARCHAR NOT NULL,
    description TEXT,
    status VARCHAR DEFAULT 'created',
    document_path VARCHAR,
    document_name VARCHAR,
    requirements_analysis TEXT,
    outline TEXT,
    sections JSON DEFAULT '[]',
    final_document_path VARCHAR,
    enable_differentiation BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä»»åŠ¡è¡¨
CREATE TABLE tasks (
    id VARCHAR PRIMARY KEY,
    project_id VARCHAR REFERENCES projects(id),
    task_type VARCHAR NOT NULL,
    status VARCHAR DEFAULT 'pending',
    config JSON DEFAULT '{}',
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    result JSON,
    error_message TEXT,
    error_traceback TEXT,
    progress INTEGER DEFAULT 0,
    current_step VARCHAR,
    total_steps INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä»»åŠ¡æ£€æŸ¥ç‚¹è¡¨
CREATE TABLE task_checkpoints (
    id VARCHAR PRIMARY KEY,
    task_id VARCHAR REFERENCES tasks(id),
    step_name VARCHAR NOT NULL,
    step_order INTEGER NOT NULL,
    state_data JSON NOT NULL,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    duration_seconds INTEGER,
    is_completed BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.1.2 ç´¢å¼•è®¾è®¡
```sql
-- æ€§èƒ½ä¼˜åŒ–ç´¢å¼•
CREATE INDEX idx_projects_status ON projects(status);
CREATE INDEX idx_projects_created_at ON projects(created_at);
CREATE INDEX idx_tasks_project_id ON tasks(project_id);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_created_at ON tasks(created_at);
CREATE INDEX idx_checkpoints_task_id ON task_checkpoints(task_id);
CREATE INDEX idx_checkpoints_step_order ON task_checkpoints(step_order);
```

### 3.2 ç¼“å­˜æ¶æ„ (Redis)

#### 3.2.1 ç¼“å­˜ç­–ç•¥
```python
# ç¼“å­˜é…ç½®
CACHE_CONFIG = {
    "task_status": {"ttl": 300},      # ä»»åŠ¡çŠ¶æ€ç¼“å­˜5åˆ†é’Ÿ
    "project_info": {"ttl": 1800},    # é¡¹ç›®ä¿¡æ¯ç¼“å­˜30åˆ†é’Ÿ
    "llm_response": {"ttl": 3600},    # LLMå“åº”ç¼“å­˜1å°æ—¶
    "document_content": {"ttl": 7200}, # æ–‡æ¡£å†…å®¹ç¼“å­˜2å°æ—¶
}
```

#### 3.2.2 æ•°æ®ç»“æ„
```
Redisæ•°æ®ç»“æ„ï¼š
â”œâ”€â”€ task:{task_id}:status          # ä»»åŠ¡çŠ¶æ€ (String)
â”œâ”€â”€ task:{task_id}:progress        # ä»»åŠ¡è¿›åº¦ (String)
â”œâ”€â”€ project:{project_id}:info      # é¡¹ç›®ä¿¡æ¯ (Hash)
â”œâ”€â”€ llm:cache:{hash}               # LLMå“åº”ç¼“å­˜ (String)
â”œâ”€â”€ celery:*                       # Celeryé˜Ÿåˆ—æ•°æ®
â””â”€â”€ session:{session_id}           # ç”¨æˆ·ä¼šè¯ (Hash)
```

### 3.3 æ–‡ä»¶å­˜å‚¨æ¶æ„

#### 3.3.1 ç›®å½•ç»“æ„
```
storage/
â”œâ”€â”€ uploads/                    # ä¸Šä¼ æ–‡ä»¶
â”‚   â”œâ”€â”€ documents/             # æ‹›æ ‡æ–‡æ¡£
â”‚   â””â”€â”€ temp/                  # ä¸´æ—¶æ–‡ä»¶
â”œâ”€â”€ outputs/                   # è¾“å‡ºæ–‡ä»¶
â”‚   â”œâ”€â”€ proposals/             # ç”Ÿæˆçš„æ–¹æ¡ˆ
â”‚   â””â”€â”€ reports/               # åˆ†ææŠ¥å‘Š
â””â”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
    â”œâ”€â”€ app.log               # åº”ç”¨æ—¥å¿—
    â”œâ”€â”€ celery.log            # Celeryæ—¥å¿—
    â””â”€â”€ error.log             # é”™è¯¯æ—¥å¿—
```

#### 3.3.2 æ–‡ä»¶ç®¡ç†ç­–ç•¥
- **å‘½åè§„èŒƒ**ï¼šæ—¶é—´æˆ³ + é¡¹ç›®ID + æ–‡ä»¶ç±»å‹
- **æ¸…ç†ç­–ç•¥**ï¼šå®šæœŸæ¸…ç†è¿‡æœŸä¸´æ—¶æ–‡ä»¶
- **å¤‡ä»½ç­–ç•¥**ï¼šé‡è¦æ–‡ä»¶è‡ªåŠ¨å¤‡ä»½
- **è®¿é—®æ§åˆ¶**ï¼šåŸºäºé¡¹ç›®çš„æ–‡ä»¶è®¿é—®æƒé™

## 4. å·¥ä½œæµå¼•æ“

### 4.1 LangGraphå·¥ä½œæµè®¾è®¡

#### 4.1.1 å·¥ä½œæµèŠ‚ç‚¹
```python
class WorkflowEngine:
    def _build_workflow(self) -> CompiledStateGraph:
        workflow = StateGraph(WorkflowState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("parse_document", self._parse_document)
        workflow.add_node("analyze_requirements", self._analyze_requirements)
        workflow.add_node("validate_requirements", self._validate_requirements)
        workflow.add_node("generate_outline", self._generate_outline)
        workflow.add_node("validate_outline", self._validate_outline)
        workflow.add_node("generate_content", self._generate_content)
        workflow.add_node("validate_content", self._validate_content)
        workflow.add_node("differentiate_content", self._differentiate_content)
        workflow.add_node("finalize", self._finalize)
        
        # è®¾ç½®æµç¨‹
        workflow.set_entry_point("parse_document")
        workflow.add_edge("parse_document", "analyze_requirements")
        # ... æ›´å¤šè¾¹çš„å®šä¹‰
        
        return workflow.compile()
```

#### 4.1.2 çŠ¶æ€ç®¡ç†
```python
class WorkflowState(BaseModel):
    project_id: str
    current_step: str
    document_content: Optional[str] = None
    requirements_analysis: Optional[str] = None
    outline: Optional[str] = None
    sections: List[Dict[str, Any]] = Field(default_factory=list)
    enable_differentiation: bool = True
    enable_validation: bool = True
    task_id: Optional[str] = None
    validation_reports: List[Dict[str, Any]] = Field(default_factory=list)
    error: Optional[str] = None
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
```

#### 4.1.3 æ£€æŸ¥ç‚¹æœºåˆ¶
```python
async def save_checkpoint(self, task_id: str, step_name: str, state: WorkflowState):
    """ä¿å­˜å·¥ä½œæµæ£€æŸ¥ç‚¹"""
    checkpoint_data = TaskCheckpointCreate(
        task_id=task_id,
        step_name=step_name,
        step_order=self.get_step_order(step_name),
        state_data=state.model_dump()
    )
    
    await persistence_service.create_checkpoint(checkpoint_data)
    logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {task_id} - {step_name}")
```

### 4.2 é”™è¯¯å¤„ç†å’Œæ¢å¤

#### 4.2.1 é”™è¯¯åˆ†ç±»
```python
class WorkflowError(Exception):
    """å·¥ä½œæµé”™è¯¯åŸºç±»"""
    pass

class DocumentParseError(WorkflowError):
    """æ–‡æ¡£è§£æé”™è¯¯"""
    pass

class LLMServiceError(WorkflowError):
    """LLMæœåŠ¡é”™è¯¯"""
    pass

class ValidationError(WorkflowError):
    """æ ¡éªŒé”™è¯¯"""
    pass
```

#### 4.2.2 æ¢å¤ç­–ç•¥
```python
async def recover_from_checkpoint(self, task_id: str) -> WorkflowState:
    """ä»æ£€æŸ¥ç‚¹æ¢å¤å·¥ä½œæµ"""
    latest_checkpoint = await persistence_service.get_latest_checkpoint(task_id)
    
    if latest_checkpoint:
        state = WorkflowState(**latest_checkpoint.state_data)
        logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤: {task_id} - {latest_checkpoint.step_name}")
        return state
    else:
        raise ValueError(f"æœªæ‰¾åˆ°ä»»åŠ¡æ£€æŸ¥ç‚¹: {task_id}")
```

## 5. AIæœåŠ¡æ¶æ„

### 5.1 LLMæœåŠ¡è®¾è®¡

#### 5.1.1 å¤šæä¾›å•†æ”¯æŒ
```python
class LLMService:
    def __init__(self):
        self.provider = toml_config.llm.provider
        self.llm = self._create_llm_client()
    
    def _create_llm_client(self):
        if self.provider == "deepseek":
            return ChatDeepSeek(
                model=toml_config.llm.model_name,
                api_key=toml_config.llm.api_key,
                temperature=0.7,
                max_tokens=4000
            )
        elif self.provider == "openai":
            return ChatOpenAI(
                model=toml_config.llm.model_name,
                api_key=toml_config.llm.api_key
            )
        # æ”¯æŒæ›´å¤šæä¾›å•†...
```

#### 5.1.2 Promptå·¥ç¨‹
```python
class PromptTemplates:
    REQUIREMENT_ANALYSIS = """
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•æ ‡ä¸“å®¶ï¼Œç²¾é€šæ‹›æŠ•æ ‡ä¸šåŠ¡ã€‚è¯·åˆ†æä»¥ä¸‹æ‹›æ ‡æ–‡æ¡£ï¼Œæå–å…³é”®éœ€æ±‚ä¿¡æ¯ã€‚
    
    è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºåˆ†æç»“æœï¼š
    1. æŠ€æœ¯éœ€æ±‚ï¼šåˆ—å‡ºæ‰€æœ‰æŠ€æœ¯è¦æ±‚å’Œè§„æ ¼
    2. åŠŸèƒ½éœ€æ±‚ï¼šåˆ—å‡ºç³»ç»ŸåŠŸèƒ½è¦æ±‚
    3. æ€§èƒ½æŒ‡æ ‡ï¼šåˆ—å‡ºæ€§èƒ½ç›¸å…³è¦æ±‚
    4. èµ„è´¨è¦æ±‚ï¼šåˆ—å‡ºæŠ•æ ‡äººèµ„è´¨è¦æ±‚
    5. è¯„åˆ†æ ‡å‡†ï¼šåˆ—å‡ºè¯„åˆ†æ ‡å‡†å’Œæƒé‡
    6. å…³é”®é£é™©ç‚¹ï¼šæ ‡è®°å¯èƒ½çš„é£é™©ç‚¹
    
    è¯·ç¡®ä¿ï¼š
    - ä¸é—æ¼ä»»ä½•å¼ºåˆ¶æ€§è¦æ±‚
    - å‡†ç¡®ç†è§£æŠ€æœ¯æœ¯è¯­
    - æ ‡è®°é‡è¦ç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
    """
    
    OUTLINE_GENERATION = """
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯æ–¹æ¡ˆæ¶æ„å¸ˆã€‚è¯·æ ¹æ®éœ€æ±‚åˆ†æç»“æœï¼Œç”Ÿæˆä¸“ä¸šçš„æŠ•æ ‡æŠ€æœ¯æ–¹æ¡ˆæçº²ã€‚
    
    æçº²è¦æ±‚ï¼š
    1. ç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
    2. è¦†ç›–æ‰€æœ‰éœ€æ±‚ç‚¹
    3. é€»è¾‘åˆç†ï¼Œç¬¦åˆæŠ•æ ‡è§„èŒƒ
    4. çªå‡ºæŠ€æœ¯ä¼˜åŠ¿å’Œåˆ›æ–°ç‚¹
    """
```

#### 5.1.3 å“åº”å¤„ç†
```python
async def _call_llm_with_prompt(self, prompt: str, **kwargs) -> str:
    """è°ƒç”¨LLMå¹¶å¤„ç†å“åº”"""
    try:
        messages = [HumanMessage(content=prompt)]
        response = await self.llm.ainvoke(messages, **kwargs)
        return response.content
    except Exception as e:
        logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
        raise LLMServiceError(f"LLMæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}")
```

### 5.2 æ–‡æ¡£å¤„ç†æœåŠ¡

#### 5.2.1 è§£æå™¨é…ç½®
```python
class DocumentParser:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", ".", "ã€‚", "!", "?", " "]
        )
    
    def parse_document(self, file_path: Path) -> Dict[str, Any]:
        loader = UnstructuredLoader(
            file_path=str(file_path),
            languages=["chi_sim", "eng"],
            strategy="fast"
        )
        documents = loader.load()
        chunks = self.text_splitter.split_documents(documents)
        
        return {
            "file_name": file_path.name,
            "file_type": file_path.suffix,
            "documents": documents,
            "chunks": chunks,
            "metadata": {
                "total_pages": len(documents),
                "total_chunks": len(chunks),
            }
        }
```

### 5.3 æ ¡éªŒæœåŠ¡

#### 5.3.1 æ ¡éªŒè§„åˆ™
```python
class ValidationService:
    async def validate_requirements_analysis(self, analysis: str, original_document: str) -> List[ValidationIssue]:
        """æ ¡éªŒéœ€æ±‚åˆ†æçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§"""
        issues = []
        
        # åŸºç¡€æ ¡éªŒ
        if len(analysis) < 100:
            issues.append(ValidationIssue(
                level=ValidationLevel.HIGH,
                result=ValidationResult.ERROR,
                message="éœ€æ±‚åˆ†æå†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸å¤Ÿè¯¦ç»†",
                suggestion="è¯·è¡¥å……æ›´è¯¦ç»†çš„éœ€æ±‚åˆ†æ"
            ))
        
        # LLMæ ¡éªŒ
        validation_result = await self._llm_validate_completeness(analysis, original_document)
        issues.extend(validation_result)
        
        return issues
```

## 6. éƒ¨ç½²æ¶æ„

### 6.1 å®¹å™¨åŒ–éƒ¨ç½²

#### 6.1.1 Dockeré…ç½®
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY pyproject.toml uv.lock ./
RUN pip install uv && uv sync --frozen

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# æš´éœ²ç«¯å£
EXPOSE 8000 7860

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 6.1.2 Docker Composeé…ç½®
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ai_bidding
      POSTGRES_USER: ai_bidding
      POSTGRES_PASSWORD: ai_bidding_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_bidding"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://ai_bidding:ai_bidding_password@postgres:5432/ai_bidding
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
```

### 6.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### 6.2.1 è´Ÿè½½å‡è¡¡é…ç½®
```nginx
upstream backend_servers {
    server backend1:8000;
    server backend2:8000;
    server backend3:8000;
}

server {
    listen 80;
    server_name ai-bidding.example.com;
    
    location /api/ {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    
    location / {
        proxy_pass http://frontend:7860;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

#### 6.2.2 ç›‘æ§é…ç½®
```yaml
# Prometheusé…ç½®
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'ai-bidding-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    
  - job_name: 'ai-bidding-celery'
    static_configs:
      - targets: ['flower:5555']
    metrics_path: '/metrics'
```

## 7. å®‰å…¨æ¶æ„

### 7.1 æ•°æ®å®‰å…¨

#### 7.1.1 æ•°æ®åŠ å¯†
- **ä¼ è¾“åŠ å¯†**ï¼šHTTPS/TLS 1.3
- **å­˜å‚¨åŠ å¯†**ï¼šæ•°æ®åº“å­—æ®µçº§åŠ å¯†
- **æ–‡ä»¶åŠ å¯†**ï¼šæ•æ„Ÿæ–‡ä»¶AES-256åŠ å¯†

#### 7.1.2 è®¿é—®æ§åˆ¶
```python
class SecurityService:
    def __init__(self):
        self.jwt_secret = os.getenv("JWT_SECRET")
        self.algorithm = "HS256"
    
    def create_access_token(self, data: dict, expires_delta: timedelta = None):
        to_encode = data.copy()
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=15)
        
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, self.jwt_secret, algorithm=self.algorithm)
        return encoded_jwt
```

### 7.2 APIå®‰å…¨

#### 7.2.1 è®¤è¯æˆæƒ
- **JWT Token**ï¼šåŸºäºJWTçš„æ— çŠ¶æ€è®¤è¯
- **è§’è‰²æƒé™**ï¼šåŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶(RBAC)
- **APIé™æµ**ï¼šé˜²æ­¢APIæ»¥ç”¨

#### 7.2.2 è¾“å…¥éªŒè¯
```python
class DocumentUploadRequest(BaseModel):
    file: UploadFile = Field(..., description="ä¸Šä¼ æ–‡ä»¶")
    
    @validator('file')
    def validate_file(cls, v):
        # æ–‡ä»¶ç±»å‹æ£€æŸ¥
        allowed_types = ['.pdf', '.docx', '.doc']
        if not any(v.filename.endswith(ext) for ext in allowed_types):
            raise ValueError('ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹')
        
        # æ–‡ä»¶å¤§å°æ£€æŸ¥
        if v.size > 50 * 1024 * 1024:  # 50MB
            raise ValueError('æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶')
        
        return v
```

### 7.3 è¿è¡Œæ—¶å®‰å…¨

#### 7.3.1 å®¹å™¨å®‰å…¨
- **æœ€å°æƒé™åŸåˆ™**ï¼šå®¹å™¨ä»¥érootç”¨æˆ·è¿è¡Œ
- **é•œåƒæ‰«æ**ï¼šå®šæœŸæ‰«æå®¹å™¨é•œåƒæ¼æ´
- **ç½‘ç»œéš”ç¦»**ï¼šå®¹å™¨ç½‘ç»œéš”ç¦»

#### 7.3.2 æ—¥å¿—å®¡è®¡
```python
class AuditLogger:
    def __init__(self):
        self.logger = logging.getLogger("audit")
    
    def log_api_access(self, user_id: str, endpoint: str, method: str, status: int):
        self.logger.info(
            f"APIè®¿é—® - ç”¨æˆ·:{user_id} ç«¯ç‚¹:{endpoint} æ–¹æ³•:{method} çŠ¶æ€:{status}",
            extra={
                "user_id": user_id,
                "endpoint": endpoint,
                "method": method,
                "status": status,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
```

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.0  
**æœ€åæ›´æ–°**ï¼š2025-07-02  
**ç»´æŠ¤äººå‘˜**ï¼šAIæŠ•æ ‡ç³»ç»Ÿå¼€å‘å›¢é˜Ÿ
